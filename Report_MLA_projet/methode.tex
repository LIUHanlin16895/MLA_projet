%\textbf{Une présentation synthétique de la solution ré-implémentée
%de l’article. Précisez et justifiez les éventuelles
%différences avec l'article de référence}\\

%\lipsum[2]

The attacker uses perturbations that are not perceptible to human vision/audition, which are sufficient to cause a normally trained model to output false predictions with high confidence, a phenomenon that researchers call adversarial attacks.

FGSM approach is a white-box attack in which the threat model assumes that the attacker has complete knowledge of his target model, including the model architecture and parameters. The attacker can therefore create an adversarial example directly on the target model by any means. FGSM is a typical one-step attack algorithm who performs a one-step update along the direction of the gradient of the adversarial loss function $J(\theta, x, y)$(i.e. the sign) to increase the loss in the steepest direction.

The aim of the FGSM attack is to disrupt the classification of the network by modifying the pixel values of the input images without modifying the network parameters. Based on the above principles of neural network computation, the loss values can be passed back to the image and the gradient $J(\theta, x, y)$as well as the direction of the gradient $sign(J(\theta, x, y))$can be calculated.The reason for using the gradient direction rather than the gradient value is to control the size of the perturbation.

The classification model updates the parameters by subtracting the gradient from the parameters so that the loss value is reduced and the probability of a correct prediction is increased. Since the attack is intended to make the network misclassify the images, it is only necessary to make the loss increase. Therefore, adding the direction of the gradient to the input image to increase the value of the loss is sufficient to interfere with the network's classification. This is the principle of the FGSM algorithm, which calculates the gradient based on the image and adds the gradient when updating the image.
\begin{equation}
    x' = x + \epsilon \cdot sign(\nabla_{x}J(\theta, x, y))
\end{equation}
$\eta = sign(\nabla_{x}J(\theta, x, y))$is the perturbation, $\epsilon$ is the weighting parameter that can be used to control the magnitude of the attack. 