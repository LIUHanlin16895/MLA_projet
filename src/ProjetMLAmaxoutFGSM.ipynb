{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBXVHNj1ecLW",
        "outputId": "86e2b8c2-dd01-4c50-8326-aeb3688c8a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW06y_wlyMyK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # 2.3\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.keras.datasets.mnist as mnist\n",
        "import time as time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import les donées 导入数据"
      ],
      "metadata": {
        "id": "t4ux8jUrycC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_image, train_labels), (test_image, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "# train_image.shape = (60000, 28, 28), train_labels.shape = (60000,)"
      ],
      "metadata": {
        "id": "e1Uu3l9JyfQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7f86b3-b757-4f6e-9904-63c9d3a009ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traitement les données 数据处理"
      ],
      "metadata": {
        "id": "uWmwF8A-yySV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisation les données 0 - 255 en -1 - 1\n",
        "train_image = (train_image - 127.5)/127.5 # 把0-255的数据范围变为-1到1之间\n",
        "test_image = (test_image - 127.5)/127.5 # 把0-255的数据范围变为-1到1之间\n",
        "\n",
        "# Augmenter la dimension du canal 增加通道维度\n",
        "#train_image = tf.expand_dims(train_image, -1)\n",
        "#test_image = tf.expand_dims(test_image, -1)\n",
        "# train_image.shape = ([60000, 28, 28, 1]), train_labels.shape = (60000,)\n",
        "\n",
        "# Transformation de type 类型转换\n",
        "train_image = tf.cast(train_image, tf.float32)\n",
        "test_image = tf.cast(test_image, tf.float32)\n",
        "train_labels = tf.cast(train_labels, tf.int64)\n",
        "test_labels = tf.cast(test_labels, tf.int64)"
      ],
      "metadata": {
        "id": "LWOBQFLQywJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Créer un jeu de données 创建数据集"
      ],
      "metadata": {
        "id": "pRnbch9czlsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建Dataset\n",
        "batchsize = 128\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_image, train_labels)).shuffle(60000).batch(batchsize)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_image, test_labels)).batch(batchsize)"
      ],
      "metadata": {
        "id": "XcjNPGxCzber"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEbTj4ngoKgz",
        "outputId": "5c6d4a2d-7713-4c8e-9ea6-9607c31b4ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(7, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for element in test_dataset:\n",
        "  print(element[1])\n",
        "\n",
        "#print(dataset[1])\n",
        "#print(test_dataset.shape)"
      ],
      "metadata": {
        "id": "rL7F2-G2T-CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construire le modèle MLP maxout et l'entraîner 搭建MLP模型并训练"
      ],
      "metadata": {
        "id": "ToW3Y0aLzkK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "def create_adversarial_img(input_image, input_label, epsilon):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(input_image)\n",
        "    prediction = model(input_image)\n",
        "    loss = loss_object(input_label, prediction)\n",
        "  gradient = tape.gradient(loss, input_image)\n",
        "  # Utiliser la fonction signe sur le gradient pour créer une perturbation对梯度使用sign函数，创建扰动\n",
        "  signed_grad = tf.sign(gradient)\n",
        "  adv_img = input_image + epsilon*signed_grad\n",
        "  adv_img = tf.clip_by_value(adv_image, -1, 1)\n",
        "  return signed_grad"
      ],
      "metadata": {
        "id": "1Gh2W_rNtBVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_out(inputs, num_units, axis=None):\n",
        "    shape = inputs.get_shape().as_list()\n",
        "    if shape[0] is None:\n",
        "        shape[0] = -1\n",
        "    if axis is None:  # Assume that channel is the last dimension\n",
        "        axis = -1\n",
        "    num_channels = shape[axis]\n",
        "    if num_channels % num_units:\n",
        "        raise ValueError('number of features({}) is not '\n",
        "                         'a multiple of num_units({})'.format(num_channels, num_units))\n",
        "    shape[axis] = num_units\n",
        "    shape += [num_channels // num_units]\n",
        "    outputs = tf.reduce_max(tf.reshape(inputs, shape), -1, keepdims=False)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "A_0auIYKyBjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
        "x = tf.keras.layers.Flatten()(inputs)\n",
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "x = tf.keras.layers.Dense(1200)(x)\n",
        "x = max_out(x, 300, axis=None)\n",
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "x = tf.keras.layers.Dense(40)(x)\n",
        "x = max_out(x, 10, axis=None)\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj7vu-ASRvxD",
        "outputId": "914aa660-7df5-4b6f-ed28-eb34d1dde941"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1200)              942000    \n",
            "                                                                 \n",
            " tf.reshape_4 (TFOpLambda)   (None, 300, 4)            0         \n",
            "                                                                 \n",
            " tf.math.reduce_max_4 (TFOpL  (None, 300)              0         \n",
            " ambda)                                                          \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 300)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 40)                12040     \n",
            "                                                                 \n",
            " tf.reshape_5 (TFOpLambda)   (None, 10, 4)             0         \n",
            "                                                                 \n",
            " tf.math.reduce_max_5 (TFOpL  (None, 10)               0         \n",
            " ambda)                                                          \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 954,150\n",
            "Trainable params: 954,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train maxout network without FGSM"
      ],
      "metadata": {
        "id": "JHmBmxqE2imz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(decay=1e-6)\n",
        "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "#optimizer = tf.optimizers.SGD(learning_rate)\n",
        "model.compile(optimizer=optimizer,loss=loss_func,metrics=['acc'])\n",
        "history = model.fit(dataset,validation_data=test_dataset,epochs=50) # 返回字典类型的数据 其中记录了准确率和损失的信息"
      ],
      "metadata": {
        "id": "BCC-h17W0Hbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa39077-bf69-482a-b08a-beffd7c9cc51"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.7256 - acc: 0.7721 - val_loss: 0.2512 - val_acc: 0.9283\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.3621 - acc: 0.8881 - val_loss: 0.1807 - val_acc: 0.9446\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.2886 - acc: 0.9104 - val_loss: 0.1488 - val_acc: 0.9538\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.2522 - acc: 0.9209 - val_loss: 0.1354 - val_acc: 0.9601\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.2299 - acc: 0.9283 - val_loss: 0.1131 - val_acc: 0.9643\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.2108 - acc: 0.9334 - val_loss: 0.1051 - val_acc: 0.9672\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1962 - acc: 0.9380 - val_loss: 0.0986 - val_acc: 0.9695\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 0.1873 - acc: 0.9409 - val_loss: 0.0933 - val_acc: 0.9717\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 19s 39ms/step - loss: 0.1785 - acc: 0.9432 - val_loss: 0.0867 - val_acc: 0.9722\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1688 - acc: 0.9471 - val_loss: 0.0870 - val_acc: 0.9731\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.1653 - acc: 0.9477 - val_loss: 0.0851 - val_acc: 0.9732\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.1578 - acc: 0.9498 - val_loss: 0.0760 - val_acc: 0.9766\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.1523 - acc: 0.9519 - val_loss: 0.0764 - val_acc: 0.9769\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.1502 - acc: 0.9524 - val_loss: 0.0766 - val_acc: 0.9765\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1450 - acc: 0.9537 - val_loss: 0.0681 - val_acc: 0.9785\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1442 - acc: 0.9533 - val_loss: 0.0734 - val_acc: 0.9782\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 0.1370 - acc: 0.9557 - val_loss: 0.0620 - val_acc: 0.9795\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.1342 - acc: 0.9574 - val_loss: 0.0744 - val_acc: 0.9774\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.1318 - acc: 0.9574 - val_loss: 0.0676 - val_acc: 0.9780\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1272 - acc: 0.9590 - val_loss: 0.0641 - val_acc: 0.9803\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.1300 - acc: 0.9579 - val_loss: 0.0644 - val_acc: 0.9798\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.1234 - acc: 0.9603 - val_loss: 0.0637 - val_acc: 0.9805\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 15s 31ms/step - loss: 0.1218 - acc: 0.9605 - val_loss: 0.0558 - val_acc: 0.9819\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 0.1171 - acc: 0.9623 - val_loss: 0.0614 - val_acc: 0.9809\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1196 - acc: 0.9611 - val_loss: 0.0577 - val_acc: 0.9807\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1160 - acc: 0.9614 - val_loss: 0.0620 - val_acc: 0.9802\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1161 - acc: 0.9631 - val_loss: 0.0584 - val_acc: 0.9820\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.1147 - acc: 0.9630 - val_loss: 0.0555 - val_acc: 0.9836\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1099 - acc: 0.9646 - val_loss: 0.0569 - val_acc: 0.9819\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1075 - acc: 0.9653 - val_loss: 0.0547 - val_acc: 0.9825\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.1098 - acc: 0.9642 - val_loss: 0.0556 - val_acc: 0.9815\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.1073 - acc: 0.9661 - val_loss: 0.0552 - val_acc: 0.9833\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 0.1043 - acc: 0.9661 - val_loss: 0.0567 - val_acc: 0.9815\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.1055 - acc: 0.9659 - val_loss: 0.0638 - val_acc: 0.9808\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 0.1045 - acc: 0.9658 - val_loss: 0.0539 - val_acc: 0.9833\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1025 - acc: 0.9667 - val_loss: 0.0559 - val_acc: 0.9831\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 23s 48ms/step - loss: 0.1015 - acc: 0.9666 - val_loss: 0.0555 - val_acc: 0.9828\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.1008 - acc: 0.9675 - val_loss: 0.0597 - val_acc: 0.9819\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0975 - acc: 0.9684 - val_loss: 0.0508 - val_acc: 0.9841\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0942 - acc: 0.9696 - val_loss: 0.0552 - val_acc: 0.9827\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.1016 - acc: 0.9673 - val_loss: 0.0541 - val_acc: 0.9830\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0952 - acc: 0.9689 - val_loss: 0.0521 - val_acc: 0.9836\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0953 - acc: 0.9678 - val_loss: 0.0529 - val_acc: 0.9854\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.0959 - acc: 0.9681 - val_loss: 0.0524 - val_acc: 0.9831\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.0944 - acc: 0.9689 - val_loss: 0.0542 - val_acc: 0.9843\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.0932 - acc: 0.9689 - val_loss: 0.0526 - val_acc: 0.9839\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.0905 - acc: 0.9700 - val_loss: 0.0539 - val_acc: 0.9831\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.0924 - acc: 0.9701 - val_loss: 0.0548 - val_acc: 0.9828\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0879 - acc: 0.9707 - val_loss: 0.0529 - val_acc: 0.9849\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.0909 - acc: 0.9699 - val_loss: 0.0510 - val_acc: 0.9842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "def loss_with_FGSM(model,input_image, input_label, epsilon=1, alpha=0.5):\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(input_image)\n",
        "      prediction = model(input_image)\n",
        "      loss = loss_object(input_label, prediction)\n",
        "    gradient = tape.gradient(loss, input_image)\n",
        "    # Utiliser la fonction signe sur le gradient pour créer une perturbation对梯度使用sign函数，创建扰动\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    adv_img = input_image + epsilon*signed_grad\n",
        "    adv_img = tf.clip_by_value(adv_img, -1, 1)\n",
        "    prediction2 = model(adv_img)\n",
        "    loss2 = loss_object(input_label, prediction2)\n",
        "    return alpha*loss + (1-alpha) * loss2"
      ],
      "metadata": {
        "id": "64Lyw9i4bbJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with loss_with_FGSM (To check)"
      ],
      "metadata": {
        "id": "PMZKSbD40wSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, epochs, optimizer, learning_rate, loss_fn, train_set, val_images, val_labels, nombre_example=60000, batchsize=128):\n",
        "\taverage_time_step = []\n",
        "\toptimizer.lr = learning_rate\n",
        "\tacc_collect = []\n",
        "\tloss_collect = []\n",
        "\tlen = int(np.floor(nombre_example / batchsize))\n",
        "\ttotal_steps = epochs*len\n",
        "\tfor epoch in range(epochs):\n",
        "\t\tif epoch > 20:\n",
        "\t\t\toptimizer.lr = learning_rate/10\n",
        "\t\tif epoch > 40:\n",
        "\t\t\toptimizer.lr = learning_rate/100\n",
        "\t\tstart_epoch = time.time()\n",
        "\t\tstep = 0\n",
        "\t\tfor element in dataset:\n",
        "\t\t\tstep = step+1\n",
        "\t\t\tstart_step = time.time()\n",
        "\t\t\timages  = element[0]\n",
        "\t\t\tlabels =element[1] \n",
        "\t\t\twith tf.GradientTape() as tape:\n",
        "\t\t\t\tloss_value = loss_with_FGSM(model, images, labels, epsilon=0.5, alpha=0.5)\n",
        "\t\t\tgrads = tape.gradient(loss_value, model.trainable_weights)\n",
        "\t\t\toptimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\t\t\tif step == len-1:\n",
        "\t\t\t\tlogits_val = model(val_images, training=True)\n",
        "\t\t\t\tlogits_val = np.argmax(logits_val, axis=-1)\n",
        "\t\t\t\tm = tf.keras.metrics.Accuracy()\n",
        "\t\t\t\tm.update_state(val_labels, logits_val)\n",
        "\t\t\t\tacc_collect.append(m.result().numpy())\n",
        "\t\t\t\tprint('epoch = ',epoch,'acc train fin epoch = ',m.result().numpy())\n",
        "\t\t\t\tloss_value_temp = loss_value._copy()\n",
        "\t\t\t\tloss_value_temp = float(loss_value_temp)\n",
        "\t\t\t\tloss_collect.append(loss_value_temp)\n",
        "\t\t\t\tprint('loss fin epoch = ',loss_value_temp)\n",
        "\tprint()\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "WuYXRGmKS525"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YBzklTR2gsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy value decreased after adding penalty. Computation time is significantly longer (Need correction)"
      ],
      "metadata": {
        "id": "GN5H9NSt0_Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = training_loop(model, epochs=10, optimizer=optimizer, learning_rate=0.001, loss_fn=loss_func, train_set=dataset, val_images=test_image, val_labels=test_labels, nombre_example=60000, batchsize=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g776IiK0f9ni",
        "outputId": "fe7d4a2f-7a30-4871-ba2b-5d7db0f479e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch =  0 acc train fin epoch =  0.3135\n",
            "loss fin epoch =  1.2127217054367065\n",
            "epoch =  1 acc train fin epoch =  0.3618\n",
            "loss fin epoch =  1.0525729656219482\n",
            "epoch =  2 acc train fin epoch =  0.4091\n",
            "loss fin epoch =  0.9534614086151123\n",
            "epoch =  3 acc train fin epoch =  0.4504\n",
            "loss fin epoch =  0.6421814560890198\n",
            "epoch =  4 acc train fin epoch =  0.4886\n",
            "loss fin epoch =  0.8858319520950317\n",
            "epoch =  5 acc train fin epoch =  0.5205\n",
            "loss fin epoch =  0.7137510776519775\n",
            "epoch =  6 acc train fin epoch =  0.599\n",
            "loss fin epoch =  0.7489454746246338\n",
            "epoch =  7 acc train fin epoch =  0.6551\n",
            "loss fin epoch =  0.5935859680175781\n",
            "epoch =  8 acc train fin epoch =  0.6792\n",
            "loss fin epoch =  0.8257623314857483\n",
            "epoch =  9 acc train fin epoch =  0.727\n",
            "loss fin epoch =  0.5658345222473145\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implémenter FGSM(Fast Gradient Sign Method)\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "BFpHhyJc0ezy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "def create_adversarial_pattern(input_image, input_label):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(input_image)\n",
        "    prediction = model(input_image)\n",
        "    loss = loss_object(input_label, prediction)\n",
        "  gradient = tape.gradient(loss, input_image)\n",
        "  # Utiliser la fonction signe sur le gradient pour créer une perturbation对梯度使用sign函数，创建扰动\n",
        "  signed_grad = tf.sign(gradient)\n",
        "  return signed_grad"
      ],
      "metadata": {
        "id": "3vk6bvar0pln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perturbations = create_adversarial_pattern(test_image, test_labels)"
      ],
      "metadata": {
        "id": "5vtW2UlZ07h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check la première perturbation 查看第一个扰动\n",
        "plt.imshow(perturbations[0],cmap='gray_r')#image en niveaux de gris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "XjXmGVG809l-",
        "outputId": "41e4431b-773c-4a0c-a5dc-c2459b9cbdea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0afe587150>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Définir une fonction pour plot les images"
      ],
      "metadata": {
        "id": "pA3Ljwcq1s2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image: Ensemble d'images originales\n",
        "# label: Ensemble d'étiquette true par le modèle d'image d'origine\n",
        "# adv_lable: Ensemble d'étiquette prédite par le modèle après l'ajout de la perturbation\n",
        "# num: Le nombre d'image d'afficher\n",
        "def display_images(image, label,adv_label, num = 10):\n",
        "  fig = plt.figure(figsize=(2*num,3)) # figsize:指定figure的宽和高，单位为英寸\n",
        "  for i in range(num):   # pre_image的shape的第一个维度就是个数，这里是num\n",
        "      plt.subplot(1,num,i+1) # 几行几列的 第i+1个图片（从1开始）\n",
        "      plt.imshow(image[i,:,:],cmap='gray') # + 1)/2) # 加1除2: 将生成的-1～1的图片弄到0-1之间,\n",
        "      plt.title('{} -> {}'.format(label[i],adv_label[i]))\n",
        "      plt.axis('off') # 不要坐标\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "EyI3rspj1riV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ajouter la perturbations et Tester dans le jeu de test"
      ],
      "metadata": {
        "id": "HZiOIcBb4ReF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tester dans les différentes valeurs d'epsilon 在不同的epsilons进行测试\n",
        "epsilons = [0,0.05,0.10,0.15,0.20,0.25,0.30]\n",
        "adv_acc_list = []\n",
        "for i, eps in enumerate(epsilons):\n",
        "  print(\"epsilons = {}:\".format(eps))\n",
        "  # Obtenir le résultat de la prédiction de l'image d'origine 获取原始图片的预测结果\n",
        "  test_image = tf.clip_by_value(test_image, -1, 1)\n",
        "  predict_label = model.predict(test_image)\n",
        "  predict_label = np.array([np.argmax(i) for i in predict_label])\n",
        "  # Générer des adversarial pattern et obtenir des résultats de prédiction 生成对抗样本，并获取预测结果\n",
        "  adv_image = test_image + eps*perturbations\n",
        "  adv_image = tf.clip_by_value(adv_image, -1, 1)\n",
        "  adv_predict_label = model.predict(adv_image)\n",
        "  adv_predict_label = np.array([np.argmax(i) for i in adv_predict_label])\n",
        "  # Évaluer le modèle sur un ensemble d'exemples adversarial 在对抗样本集合中评估模型\n",
        "  score = model.evaluate(adv_image,test_labels,verbose=0)\n",
        "  adv_acc_list.append(score[1])\n",
        "  # plot\n",
        "  display_images(adv_image,predict_label,adv_predict_label, 10)"
      ],
      "metadata": {
        "id": "FI9qIhF14o17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with adverseral example\n"
      ],
      "metadata": {
        "id": "udm_XeyLCyPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perturb = create_adversarial_pattern(train_image, train_labels)\n",
        "train_adv = train_image+0.3*perturb\n",
        "train_train_adv = tf.concat([train_image, train_adv], 0) #对抗训练集 = 原训练集+加了扰动的训练集 （120000 images） \n",
        "print(np.shape(train_train_adv))\n",
        "labels_label_adv = tf.concat([train_labels, train_labels], 0)  #labels = 2*原labels，因为加了扰动的图像还属于该标签"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv_DoY9VDmnZ",
        "outputId": "0799f477-0cce-4f84-ab5f-6dfda809266a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_adv = tf.data.Dataset.from_tensor_slices((train_train_adv, labels_label_adv)).shuffle(120000).batch(256)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_image, test_labels)).batch(256)"
      ],
      "metadata": {
        "id": "WFZSStP_DPmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
        "x = tf.keras.layers.Flatten()(inputs)\n",
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "x = tf.keras.layers.Dense(1200)(x)\n",
        "x = max_out(x, 300, axis=None)\n",
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "x = tf.keras.layers.Dense(40)(x)\n",
        "x = max_out(x, 10, axis=None)\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model_adv = tf.keras.Model(inputs, outputs)\n",
        "model_adv.summary()"
      ],
      "metadata": {
        "id": "g5d-czkOCyii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tester dans les différentes valeurs d'epsilon 在不同的epsilons进行测试\n",
        "epsilons = [0,0.05,0.10,0.15,0.20,0.25,0.30]\n",
        "adv_acc_list = []\n",
        "acc_list = []\n",
        "for i, eps in enumerate(epsilons):\n",
        "  print(\"epsilons = {}:\".format(eps))\n",
        "  adv_image = test_image + eps*perturbations      # 对抗样本测试集=测试集加上干扰\n",
        "  adv_image = tf.clip_by_value(adv_image, -1, 1)\n",
        "  # Obtenir le résultat de la prédiction de l'image d'origine 获取原始图片的预测结果\n",
        "  #test_image = tf.clip_by_value(adv_image, -1, 1)\n",
        "  predict_label = model.predict(adv_image) \n",
        "  predict_label = np.array([np.argmax(i) for i in predict_label])\n",
        "  # Générer des adversarial pattern et obtenir des résultats de prédiction 生成对抗样本，并获取预测结果\n",
        "  adv_predict_label = model_adv.predict(adv_image)\n",
        "  adv_predict_label = np.array([np.argmax(i) for i in adv_predict_label])\n",
        "  # Évaluer le modèle sur un ensemble d'exemples adversarial 在对抗样本集合中评估模型\n",
        "  score1 = model.evaluate(adv_image,test_labels,verbose=0)\n",
        "  acc_list.append(score1[1])\n",
        "  score = model_adv.evaluate(adv_image,test_labels,verbose=0)\n",
        "  adv_acc_list.append(score[1])\n",
        "  # plot\n",
        "  display_images(adv_image,predict_label,adv_predict_label, 10)\n",
        "\n",
        "  ## 输出标签：原模型对对抗样例的预测 -> 用对抗训练的模型对对抗样例的预测"
      ],
      "metadata": {
        "id": "rfqm8okECrmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afficher la précision en fonction d'epsilons"
      ],
      "metadata": {
        "id": "b0djFhXo9wxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(epsilons,adv_acc_list,label='acc_model_adv')\n",
        "plt.plot(epsilons,acc_list,label='acc_model')\n",
        "plt.title(\"The Accuracy of Adversarial Samples\")\n",
        "plt.xlabel(\"epsilons\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "print('acc',adv_acc_list)\n",
        "print('epsilons',epsilons)"
      ],
      "metadata": {
        "id": "yVR23TEt7OGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# "
      ],
      "metadata": {
        "id": "vllBuERS-BEX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}