
The paper "Explaining and Exploiting Adversarial Examples" proposes a new explanation for the existence of machine learning models, including neural networks, for adversarial examples, which is the linearity assumption. Also, the paper proposes a simple adversarial example generation method-FGSM-and then uses the adversarial examples generated by this attack method for adversarial training. By reproducing the results, we first implement the FGSM method and verify the existence of adversarial examples, and then implement several different effective defense methods for different networks. Overall, this paper provides a new perspective on the phenomenon of adversarial examples and offers new defense solutions to reduce their impact.\\

%\lipsum[7]